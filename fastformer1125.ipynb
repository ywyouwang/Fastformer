{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHBHa9ThCjhK",
    "outputId": "63af514d-8278-4ebe-e56a-114b964848be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOcmpu8tCykN",
    "outputId": "2ac4864b-bc33-4a21-eb7f-68f03b16f6d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/nlp_final_project_fastformer\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/nlp_final_project_fastformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9ZInjmjFGY7"
   },
   "source": [
    "### Load packages and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLpeMmPkDEDb",
    "outputId": "490ad032-1654-43e6-83ac-225fa4c9bae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5 MB 15.1 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 96.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 83.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bk7UY9F4DHm6",
    "outputId": "a5548687-9e10-49d5-ea0f-b15717c1d0d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
      "\u001b[K     |████████████████████████████████| 451 kB 14.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[K     |████████████████████████████████| 212 kB 75.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.11.0)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 59.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.11.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 77.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "Successfully installed datasets-2.7.1 multiprocess-0.70.14 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hl4W_If2Yv69"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, einsum\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from transformers import BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertSelfOutput, BertIntermediate, BertOutput\n",
    "from random import shuffle\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oI_ga-cHDqP-"
   },
   "outputs": [],
   "source": [
    "config=BertConfig.from_json_file('fastformer.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTlHmoYRQT_c"
   },
   "source": [
    "### Load pretrain embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "25C_hDgYRjgU"
   },
   "outputs": [],
   "source": [
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# !unzip glove.6B.zip\n",
    "# !ls -lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8s5hf-A-Twpo"
   },
   "outputs": [],
   "source": [
    "class WordEmbeddings:\n",
    "    \"\"\"\n",
    "    Wraps an Indexer and a list of 1-D numpy arrays where each position in the list is the vector for the corresponding\n",
    "    word in the indexer. The 0 vector is returned if an unknown word is queried.\n",
    "    \"\"\"\n",
    "    def __init__(self, word_indexer, vectors):\n",
    "        self.word_indexer = word_indexer\n",
    "        self.vectors = vectors\n",
    "\n",
    "    def get_initialized_embedding_layer(self):\n",
    "        return torch.nn.Embedding.from_pretrained(torch.FloatTensor(self.vectors))\n",
    "\n",
    "    def get_embedding_length(self):\n",
    "        return len(self.vectors[0])\n",
    "\n",
    "    # def get_embedding(self, word):\n",
    "    def get_embedding(self, word_idx):\n",
    "        \"\"\"\n",
    "        Returns the embedding for a given word\n",
    "        :param word: The word to look up\n",
    "        :return: The UNK vector if the word is not in the Indexer or the vector otherwise\n",
    "        \"\"\"\n",
    "        # word_idx = self.word_indexer.index_of(word)\n",
    "        if word_idx != -1:\n",
    "            return self.vectors[word_idx]\n",
    "        else:\n",
    "            return self.vectors[self.word_indexer.index_of(\"UNK\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5JCtn_d2T4n3"
   },
   "outputs": [],
   "source": [
    "def read_word_embeddings(embeddings_file: str) -> WordEmbeddings:\n",
    "    \"\"\"\n",
    "    Loads the given embeddings (ASCII-formatted) into a WordEmbeddings object. Augments this with an UNK embedding\n",
    "    that is the 0 vector. Reads in all embeddings with no filtering -- you should only use this for relativized\n",
    "    word embedding files.\n",
    "    :param embeddings_file: path to the file containing embeddings\n",
    "    :return: WordEmbeddings object reflecting the words and their embeddings\n",
    "    \"\"\"\n",
    "    f = open(embeddings_file)\n",
    "    word_indexer = Indexer()\n",
    "    vectors = []\n",
    "    # Make position 0 a PAD token, which can be useful if you\n",
    "    word_indexer.add_and_get_index(\"PAD\")\n",
    "    # Make position 1 the UNK token\n",
    "    word_indexer.add_and_get_index(\"UNK\")\n",
    "    for line in f:\n",
    "        if line.strip() != \"\":\n",
    "            space_idx = line.find(' ')\n",
    "            word = line[:space_idx]\n",
    "            numbers = line[space_idx+1:]\n",
    "            float_numbers = [float(number_str) for number_str in numbers.split()]\n",
    "            vector = np.array(float_numbers)\n",
    "            word_indexer.add_and_get_index(word)\n",
    "            # Append the PAD and UNK vectors to start. Have to do this weirdly because we need to read the first line\n",
    "            # of the file to see what the embedding dim is\n",
    "            if len(vectors) == 0:\n",
    "                vectors.append(np.zeros(vector.shape[0]))\n",
    "                vectors.append(np.zeros(vector.shape[0]))\n",
    "            vectors.append(vector)\n",
    "    f.close()\n",
    "    print(\"Read in \" + repr(len(word_indexer)) + \" vectors of size \" + repr(vectors[0].shape[0]))\n",
    "    # Turn vectors into a 2-D numpy array\n",
    "    return WordEmbeddings(word_indexer, np.array(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KTLCw65UUNHG",
    "outputId": "b14b2176-206e-480c-d2dd-412676722ec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 400002 vectors of size 50\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = read_word_embeddings(\"glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c6w1x2fkYc3",
    "outputId": "14b03168-e166-44c7-d5d1-b527a362d31a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 400002 vectors of size 100\n"
     ]
    }
   ],
   "source": [
    "word_embeddings_100 = read_word_embeddings(\"glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7b13m3LkY6Z",
    "outputId": "45c5cbf6-573c-4e6f-ba8a-74e5f040c177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 400002 vectors of size 200\n"
     ]
    }
   ],
   "source": [
    "word_embeddings_200 = read_word_embeddings(\"glove.6B.200d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cS34ehH1kd3c",
    "outputId": "df4b68f8-a678-4b4c-a010-eb15472d8709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 400002 vectors of size 300\n"
     ]
    }
   ],
   "source": [
    "word_embeddings_300 = read_word_embeddings(\"glove.6B.300d.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhJJ9KcrEKSR"
   },
   "source": [
    "### Build Fastformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GwaWEFHrbphB"
   },
   "outputs": [],
   "source": [
    "config=BertConfig.from_json_file('fastformer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vKtDbfr4vwLQ"
   },
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.att_fc1 = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.att_fc2 = nn.Linear(config.hidden_size, 1)\n",
    "        self.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "            \n",
    "                \n",
    "    def forward(self, x, attn_mask=None):\n",
    "        bz = x.shape[0]\n",
    "        e = self.att_fc1(x)\n",
    "        e = nn.Tanh()(e)\n",
    "        alpha = self.att_fc2(e)\n",
    "        alpha = torch.exp(alpha)\n",
    "        if attn_mask is not None:\n",
    "            alpha = alpha * attn_mask.unsqueeze(2)\n",
    "        alpha = alpha / (torch.sum(alpha, dim=1, keepdim=True) + 1e-8)\n",
    "        x = torch.bmm(x.permute(0, 2, 1), alpha)\n",
    "        x = torch.reshape(x, (bz, -1))  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6_nVgSY2vzMk"
   },
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        if config.hidden_size % config.num_attention_heads != 0:\n",
    "            raise ValueError(\n",
    "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
    "                \"heads (%d)\" %\n",
    "                (config.hidden_size, config.num_attention_heads))\n",
    "            \n",
    "        self.attention_head_size = int(config.hidden_size /config.num_attention_heads)\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "        self.emb_dim = config.hidden_size\n",
    "#         self.emb_dim = 50\n",
    "\n",
    "        self.query = nn.Linear(self.emb_dim, self.all_head_size)\n",
    "        self.query_att = nn.Linear(self.all_head_size, self.num_attention_heads)\n",
    "\n",
    "        self.key = nn.Linear(self.emb_dim, self.all_head_size)\n",
    "        self.key_att = nn.Linear(self.all_head_size, self.num_attention_heads)\n",
    "\n",
    "        self.value = nn.Linear(self.emb_dim, self.all_head_size)\n",
    "\n",
    "        self.transform = nn.Linear(self.all_head_size, self.all_head_size)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "        self.param_sharing = config.param_sharing\n",
    "\n",
    "    def init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "                \n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads,self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "    \n",
    "    def forward(self, input, attention_mask):\n",
    "        # input:(batch_size, seq_len, emb_dim)\n",
    "        batch_size, seq_len, _ = input.shape\n",
    "\n",
    "        # concatenated Q matrix for all heads (batch_size, seq_len, all_head_size)\n",
    "        concat_Q = self.query(input)\n",
    "        # concatenated K matrix for all heads (batch_size, seq_len, all_head_size)\n",
    "        concat_K = self.key(input)\n",
    "\n",
    "        # (batch_size, num_head, seq_len)\n",
    "        query_for_score = self.query_att(concat_Q).transpose(1, 2) / self.attention_head_size**0.5\n",
    "        # add attention mask\n",
    "        query_for_score += attention_mask\n",
    "\n",
    "        # the weight alpha : (batch_size, num_head, 1, seq_len)\n",
    "        query_weight = self.softmax(query_for_score).unsqueeze(2)\n",
    "\n",
    "        # (batch_size, num_head, seq_len, head_dim)\n",
    "        byhead_Q = self.transpose_for_scores(concat_Q)\n",
    "        # weighted sum of q, get the global representation of q \n",
    "        # after transpose: (batch_size, 1, num_head, head_dim)\n",
    "        # after view: (batch_size, 1, num_head* head_dim)\n",
    "        global_q = torch.matmul(query_weight, byhead_Q).transpose(1, 2).view(-1,1,self.num_attention_heads*self.attention_head_size)\n",
    "        # (batch_size, seq_len, num_head* head_dim)\n",
    "        global_q_matrix = global_q.repeat(1, seq_len,1)\n",
    "        \n",
    "\n",
    "        # global q dot product with k (batch_size, seq_len, all_head_size)\n",
    "        P = concat_K * global_q_matrix\n",
    "        # (batch_size, num_head, seq_len)\n",
    "        P_for_score = (self.key_att(P)/ self.attention_head_size**0.5).transpose(1, 2)\n",
    "        # add attention mask\n",
    "        P_for_score +=attention_mask\n",
    "\n",
    "        # the weight beta (batch_size, num_head, 1, seq_len)\n",
    "        query_key_weight = self.softmax(P_for_score).unsqueeze(2)\n",
    "        # (batch_size, num_head, seq_len, head_dim)\n",
    "        byhead_P = self.transpose_for_scores(P)\n",
    "        # (batch_size, num_head, 1, head_dim)\n",
    "        global_k = torch.matmul(query_key_weight, byhead_P)\n",
    "\n",
    "        if self.param_sharing:\n",
    "            # query-value parameter sharing\n",
    "            # (batch_size, num_head, 1, head_dim) (batch_size, num_head, seq_len, head_dim) -> (batch_size, num_head, seq_len, head_dim)\n",
    "            # after transpose: (batch_size, seq_len, num_head,  head_dim)\n",
    "            weighted_value =(global_k * byhead_Q).transpose(1, 2)\n",
    "\n",
    "        else:\n",
    "            # without query value param sharing\n",
    "            concat_V = self.value(input)\n",
    "            byhead_V = self.transpose_for_scores(concat_V)\n",
    "\n",
    "            weighted_value =(global_k * byhead_V).transpose(1, 2)\n",
    "\n",
    "\n",
    "        # (batch_size, seq_len, num_head*head_dim)\n",
    "        weighted_value = weighted_value.reshape(weighted_value.size()[:-2] + (self.num_attention_heads * self.attention_head_size,))\n",
    "        # add the original Q as a residual\n",
    "        weighted_value = self.transform(weighted_value) + concat_Q\n",
    "      \n",
    "        return weighted_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "e7mAdHpEv4S7"
   },
   "outputs": [],
   "source": [
    "class FastAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FastAttention, self).__init__()\n",
    "        self.self = AdditiveAttention(config)\n",
    "        self.output = BertSelfOutput(config)\n",
    "\n",
    "    def forward(self, input_tensor, attention_mask):\n",
    "        self_output = self.self(input_tensor, attention_mask)\n",
    "        attention_output = self.output(self_output, input_tensor)\n",
    "        return attention_output\n",
    "\n",
    "class FastformerLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FastformerLayer, self).__init__()\n",
    "        self.attention = FastAttention(config)\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        attention_output = self.attention(hidden_states, attention_mask)\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        return layer_output\n",
    "\n",
    "class FastformerEncoder(nn.Module):\n",
    "    def __init__(self, config, pooler_count=1):\n",
    "        super(FastformerEncoder, self).__init__()\n",
    "        self.config = config\n",
    "        self.encoders = nn.ModuleList([FastformerLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "#         self.position_embeddings = nn.Embedding(config.max_position_embeddings, 50)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "        # support multiple different poolers with shared bert encoder.\n",
    "        self.poolers = nn.ModuleList()\n",
    "        if config.pooler_type == 'weightpooler':\n",
    "            for _ in range(pooler_count):\n",
    "                self.poolers.append(AttentionPooling(config))\n",
    "        # logging.info(f\"This model has {len(self.poolers)} poolers.\")\n",
    "\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if isinstance(module, (nn.Embedding)) and module.padding_idx is not None:\n",
    "                with torch.no_grad():\n",
    "                    module.weight[module.padding_idx].fill_(0)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, \n",
    "                input_embs, \n",
    "                attention_mask, \n",
    "                pooler_index=0):\n",
    "        #input_embs: batch_size, seq_len, emb_dim\n",
    "        #attention_mask: batch_size, seq_len, emb_dim\n",
    "\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1)\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        batch_size, seq_length, emb_dim = input_embs.shape\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_embs.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand(batch_size, -1)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "\n",
    "        embeddings = input_embs + position_embeddings\n",
    "        \n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        #print(embeddings.size())\n",
    "        all_hidden_states = [embeddings]\n",
    "\n",
    "        for i, layer_module in enumerate(self.encoders):\n",
    "            layer_outputs = layer_module(all_hidden_states[-1], extended_attention_mask)\n",
    "            all_hidden_states.append(layer_outputs)\n",
    "        assert len(self.poolers) > pooler_index\n",
    "        output = self.poolers[pooler_index](all_hidden_states[-1], attention_mask)\n",
    "\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1fMczNbccXPC"
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,config,outclasses,num_tokens):\n",
    "        super(Model, self).__init__()\n",
    "        self.config = config\n",
    "        self.word_embedding = nn.Embedding(num_tokens,config.hidden_size,padding_idx=0)\n",
    "        self.fastformer_model = FastformerEncoder(config)\n",
    "        self.dense_linear = nn.Linear(config.hidden_size,outclasses)\n",
    "        self.criterion = nn.CrossEntropyLoss() \n",
    "        self.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if isinstance(module, (nn.Embedding)) and module.padding_idx is not None:\n",
    "                with torch.no_grad():\n",
    "                    module.weight[module.padding_idx].fill_(0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "    \n",
    "    def forward(self,input_ids,targets):\n",
    "        mask=input_ids.bool().float()\n",
    "        embds=self.word_embedding(input_ids)\n",
    "        text_vec = self.fastformer_model(embds,mask)\n",
    "        score = self.dense_linear(text_vec)\n",
    "        loss = self.criterion(score, targets) \n",
    "        return loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cFo3kZKGPO-8"
   },
   "outputs": [],
   "source": [
    "class Model_pretrained_emb(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,config,outclasses,embeddings: word_embeddings,pretrained_emb_dim):\n",
    "        super(Model_pretrained_emb, self).__init__()\n",
    "        self.config = config\n",
    "        # self.word_embedding = nn.Embedding(num_tokens,config.hidden_size,padding_idx=0)\n",
    "        self.word_embedding = embeddings\n",
    "        self.transform = nn.Linear(pretrained_emb_dim,config.hidden_size)\n",
    "        self.fastformer_model = FastformerEncoder(config)\n",
    "        self.dense_linear = nn.Linear(config.hidden_size,outclasses)\n",
    "        self.criterion = nn.CrossEntropyLoss() \n",
    "        self.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if isinstance(module, (nn.Embedding)) and module.padding_idx is not None:\n",
    "                with torch.no_grad():\n",
    "                    module.weight[module.padding_idx].fill_(0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "    \n",
    "    def forward(self,input_ids,targets):\n",
    "\n",
    "        \n",
    "        mask = input_ids.bool().float()\n",
    "\n",
    "\n",
    "        batch_emb = []\n",
    "        for batch in range(len(input_ids)):\n",
    "          embds = []\n",
    "          for word in input_ids[batch]:\n",
    "              embds.append(self.word_embedding.get_embedding(word))\n",
    "          batch_emb.append(embds)\n",
    "\n",
    "        embds_tensor = torch.FloatTensor(np.array(batch_emb)).cuda()\n",
    "\n",
    "        trans_embds = self.transform(embds_tensor)\n",
    "\n",
    "        text_vec = self.fastformer_model(trans_embds,mask)\n",
    "        score = self.dense_linear(text_vec)\n",
    "        loss = self.criterion(score, targets) \n",
    "        return loss, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-FpvrNSE5Pi"
   },
   "source": [
    "### Build training and testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KoBeRa3zcbLS"
   },
   "outputs": [],
   "source": [
    "def acc(y_true, y_hat):\n",
    "    y_hat = torch.argmax(y_hat, dim=-1)\n",
    "    tot = y_true.shape[0]\n",
    "    hit = torch.sum(y_true == y_hat)\n",
    "    return hit.data.float() * 1.0 / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "l1vYBgwiCi5V"
   },
   "outputs": [],
   "source": [
    "# def train(epochs, data, label, train_index, val_index):\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "        \n",
    "#         shuffle(train_index)\n",
    "#         loss = 0.0\n",
    "#         accuary = 0.0\n",
    "#         train_acc = []\n",
    "#         train_loss = []\n",
    "#         train_allpred = []\n",
    "\n",
    "#         for cnt in range(len(train_index)//64):\n",
    "\n",
    "#             log_ids = data[train_index][cnt*64:cnt*64+64,:256]\n",
    "#             targets = label[train_index][cnt*64:cnt*64+64]\n",
    "\n",
    "#             log_ids = torch.LongTensor(log_ids).cuda(non_blocking=True)\n",
    "#             targets = torch.LongTensor(targets).cuda(non_blocking=True)\n",
    "\n",
    "#             bz_loss, y_hat = model(log_ids, targets)\n",
    "#             train_allpred += y_hat.to('cpu').detach().numpy().tolist()\n",
    "\n",
    "#             loss += bz_loss.data.float()\n",
    "#             accuary += acc(targets, y_hat)\n",
    "\n",
    "#             train_loss.append(bz_loss.data.float())\n",
    "#             train_acc.append(accuary)\n",
    "\n",
    "            \n",
    "#             unified_loss=bz_loss\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             unified_loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             if cnt % 1000 == 0:\n",
    "#                 print( ' Ed: {}, train_loss: {:.5f}, acc: {:.5f}'.format(cnt * 64, loss.data / (cnt+1), accuary / (cnt+1)))\n",
    "\n",
    "#         y_pred_train = np.argmax(train_allpred,axis=-1)\n",
    "#         y_true_train = label[val_index]\n",
    "\n",
    "#         model.eval()\n",
    "        \n",
    "#         allpred=[]\n",
    "#         val_loss = []\n",
    "\n",
    "#         for cnt in range(len(val_index)//64+1):\n",
    "        \n",
    "#             val_log_ids=news_words[val_index][cnt*64:cnt*64+64,:256]\n",
    "#             val_targets= label[val_index][cnt*64:cnt*64+64]\n",
    "#             val_log_ids = torch.LongTensor(val_log_ids).cuda(non_blocking=True)\n",
    "#             val_targets = torch.LongTensor(val_targets).cuda(non_blocking=True)\n",
    "        \n",
    "#             bz_loss2, y_hat2 = model(val_log_ids, val_targets)\n",
    "#             val_loss.append(bz_loss2)\n",
    "#             allpred += y_hat2.to('cpu').detach().numpy().tolist()\n",
    "            \n",
    "#         y_pred = np.argmax(allpred,axis=-1)\n",
    "#         y_true = label[val_index]\n",
    "\n",
    "#         print('Epoch {} train loss'.format(epoch),sum(train_loss)/len(train_loss))\n",
    "#         print('Epoch {} val accuracy'.format(epoch),sum(train_acc)/len(train_acc))\n",
    "#         print('Epoch {} val Macro-F'.format(epoch),f1_score(y_true_train, y_pred_train ,average = 'macro'))\n",
    "\n",
    "\n",
    "#         print('Epoch {} val loss'.format(epoch),sum(val_loss)/len(val_loss))\n",
    "#         print('Epoch {} val accuracy'.format(epoch),accuracy_score(y_true, y_pred))\n",
    "#         print('Epoch {} val Macro-F'.format(epoch),f1_score(y_true, y_pred,average = 'macro'))\n",
    "        \n",
    "#         model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Iutt0QQ3cyVP"
   },
   "outputs": [],
   "source": [
    "def train(epochs, data, label, train_index,val_index):\n",
    "\n",
    "\n",
    "    train_loss_cache = []\n",
    "    train_acc_cache = []\n",
    "    train_f1_cache = []\n",
    "\n",
    "    val_loss_cache = []\n",
    "    val_acc_cache = []\n",
    "    val_f1_cache= []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        loss = 0.0\n",
    "        accuary = 0.0\n",
    "\n",
    "        train_allpred = []\n",
    "\n",
    "        np.random.shuffle(train_index) \n",
    "\n",
    "        for cnt in range(len(train_index)//64):\n",
    "\n",
    "            log_ids = data[train_index][cnt*64:cnt*64+64,:config.max_position_embeddings]\n",
    "            targets = label[train_index][cnt*64:cnt*64+64]\n",
    "\n",
    "            log_ids = torch.LongTensor(log_ids).cuda(non_blocking=True)\n",
    "            targets = torch.LongTensor(targets).cuda(non_blocking=True)\n",
    "\n",
    "            bz_loss, y_hat = model(log_ids, targets)\n",
    "            train_allpred += y_hat.to('cpu').detach().numpy().tolist()\n",
    "\n",
    "            loss += bz_loss.data.float()\n",
    "            accuary += acc(targets, y_hat)\n",
    "\n",
    "            unified_loss=bz_loss\n",
    "            optimizer.zero_grad()\n",
    "            unified_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if cnt % 200== 0:\n",
    "                print( ' Ed: {}, train_loss: {:.5f}, acc: {:.5f}'.format(cnt * 64, loss.data / (cnt+1), accuary / (cnt+1)))\n",
    "\n",
    "        y_pred_train = np.argmax(train_allpred,axis=-1)\n",
    "        y_true_train = label[train_index]  \n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        allpred=[]\n",
    "        val_loss = []\n",
    "\n",
    "        for cnt in range(len(val_index)//64+1):\n",
    "        \n",
    "            log_ids = data[val_index][cnt*64:cnt*64+64,:config.max_position_embeddings]\n",
    "            targets = label[val_index][cnt*64:cnt*64+64]\n",
    "            log_ids = torch.LongTensor(log_ids).cuda(non_blocking=True)\n",
    "            targets = torch.LongTensor(targets).cuda(non_blocking=True)\n",
    "        \n",
    "            bz_loss2, y_hat2 = model(log_ids, targets)\n",
    "            val_loss.append(bz_loss2.data.float())\n",
    "            allpred+=y_hat2.to('cpu').detach().numpy().tolist()\n",
    "            \n",
    "        y_pred = np.argmax(allpred,axis=-1)\n",
    "        y_true = label[val_index]\n",
    "\n",
    "        # print(accuracy_score(y_true, y_pred))\n",
    "        print('Epoch {} val accuracy'.format(epoch),accuracy_score(y_true, y_pred))\n",
    "        print('Epoch {} val Macro-F'.format(epoch),f1_score(y_true, y_pred,average = 'macro'))\n",
    "\n",
    "        train_loss_cache.append(loss.data / (cnt+1))\n",
    "        train_acc_cache.append(accuary / (cnt+1))\n",
    "        train_f1_cache.append(f1_score(y_true_train, y_pred_train ,average = 'macro'))\n",
    "\n",
    "        val_loss_cache.append(sum(val_loss)/len(val_loss))\n",
    "        val_acc_cache.append(accuracy_score(y_true, y_pred))\n",
    "        val_f1_cache.append(f1_score(y_true, y_pred,average = 'macro'))\n",
    "\n",
    "        model.train()\n",
    "\n",
    "    cache = {'train_loss':train_loss_cache,'train_acc':train_acc_cache,'train_f1':train_f1_cache,\n",
    "             'val_loss':val_loss_cache, 'val_acc':val_acc_cache, 'val_f1':val_f1_cache}\n",
    "    return cache, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6PeAj5YPQKGD"
   },
   "outputs": [],
   "source": [
    "def test(model, data, label, test_index):\n",
    "    \n",
    "    model.eval()\n",
    "    allpred = []\n",
    "    for cnt in range(len(test_index)//64+1):\n",
    "\n",
    "        log_ids = data[test_index][cnt*64:cnt*64+64,:config.max_position_embeddings]\n",
    "        targets= label[test_index][cnt*64:cnt*64+64]\n",
    "        log_ids = torch.LongTensor(log_ids).cuda(non_blocking=True)\n",
    "        targets = torch.LongTensor(targets).cuda(non_blocking=True)\n",
    "\n",
    "        bz_loss3, y_hat3 = model(log_ids, targets)\n",
    "#         allpred += y_hat3\n",
    "        allpred += y_hat3.to('cpu').detach().numpy().tolist()\n",
    "\n",
    "    y_pred = np.argmax(allpred,axis=-1)\n",
    "    y_true = label[test_index]\n",
    "\n",
    "    print('test accuracy',accuracy_score(y_true, y_pred))\n",
    "    print('test Macro-F',f1_score(y_true, y_pred,average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "groWcxIitBTR"
   },
   "outputs": [],
   "source": [
    "def plot_figure(with_param_sharing,without_param_sharing,labels,set):\n",
    "    plt.rcParams['axes.labelsize'] = 16  # xy轴label的size\n",
    "    plt.rcParams['xtick.labelsize'] = 12  # x轴ticks的size\n",
    "    plt.rcParams['ytick.labelsize'] = 14  # y轴ticks的size\n",
    "    # plt.rcParams['legend.fontsize'] = 12  # 图例的size\n",
    "\n",
    "\n",
    "    width = 0.3  # 柱形的宽度\n",
    "    x1_list = []\n",
    "    x2_list = []\n",
    "    for i in range(len(with_param_sharing)):\n",
    "        x1_list.append(i)\n",
    "        x2_list.append(i + width)\n",
    "\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_ylim(0, 0.6)\n",
    "    a1 = ax1.bar(x1_list, with_param_sharing, width=width, color='lightcoral', align='edge', label = 'w/ param share')\n",
    "\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels()) \n",
    "    ax1.set_title('Accuracy and Macro-F on {} set'.format(set),fontsize = 14)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Macro-F')\n",
    "    ax2.set_ylim(0, 0.6)\n",
    "    a2 = ax2.bar(x2_list, without_param_sharing, width=width, color='lightblue', align='edge', tick_label=labels,label = 'w/o param share ')\n",
    "\n",
    "\n",
    "    plt.legend(handles = [a1,a2])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yelp Fine Grained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359c78f557d94b74af1d56da8b4994a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66ad1630c794ff78b54733be10c0d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83d9fa7c034464b8b75a9a8b7ea1524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset yelp_review_full/yelp_review_full to C:/Users/You Wang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249dacfc5ea149c69fb2aaa4c76441a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/196M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset yelp_review_full downloaded and prepared to C:/Users/You Wang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e825de4e860742559bb005d602af9740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('yelp_review_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[]\n",
    "label=[]\n",
    "for row in dataset['train']['text'][:40000]+dataset['test']['text'][:10000]:\n",
    "    text.append(wordpunct_tokenize(row.lower()))\n",
    "for row in dataset['train']['label'][:40000]+dataset['test']['label'][:10000]:\n",
    "    label.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = []\n",
    "for sample in text:\n",
    "    sample = sample[:512]\n",
    "    new_text.append(sample+['PAD']*(512-len(sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dr',\n",
       " '.',\n",
       " 'goldberg',\n",
       " 'offers',\n",
       " 'everything',\n",
       " 'i',\n",
       " 'look',\n",
       " 'for',\n",
       " 'in',\n",
       " 'a',\n",
       " 'general',\n",
       " 'practitioner',\n",
       " '.',\n",
       " 'he',\n",
       " \"'\",\n",
       " 's',\n",
       " 'nice',\n",
       " 'and',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'to',\n",
       " 'without',\n",
       " 'being',\n",
       " 'patronizing',\n",
       " ';',\n",
       " 'he',\n",
       " \"'\",\n",
       " 's',\n",
       " 'always',\n",
       " 'on',\n",
       " 'time',\n",
       " 'in',\n",
       " 'seeing',\n",
       " 'his',\n",
       " 'patients',\n",
       " ';',\n",
       " 'he',\n",
       " \"'\",\n",
       " 's',\n",
       " 'affiliated',\n",
       " 'with',\n",
       " 'a',\n",
       " 'top',\n",
       " '-',\n",
       " 'notch',\n",
       " 'hospital',\n",
       " '(',\n",
       " 'nyu',\n",
       " ')',\n",
       " 'which',\n",
       " 'my',\n",
       " 'parents',\n",
       " 'have',\n",
       " 'explained',\n",
       " 'to',\n",
       " 'me',\n",
       " 'is',\n",
       " 'very',\n",
       " 'important',\n",
       " 'in',\n",
       " 'case',\n",
       " 'something',\n",
       " 'happens',\n",
       " 'and',\n",
       " 'you',\n",
       " 'need',\n",
       " 'surgery',\n",
       " ';',\n",
       " 'and',\n",
       " 'you',\n",
       " 'can',\n",
       " 'get',\n",
       " 'referrals',\n",
       " 'to',\n",
       " 'see',\n",
       " 'specialists',\n",
       " 'without',\n",
       " 'having',\n",
       " 'to',\n",
       " 'see',\n",
       " 'him',\n",
       " 'first',\n",
       " '.',\n",
       " 'really',\n",
       " ',',\n",
       " 'what',\n",
       " 'more',\n",
       " 'do',\n",
       " 'you',\n",
       " 'need',\n",
       " '?',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'sitting',\n",
       " 'here',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'think',\n",
       " 'of',\n",
       " 'any',\n",
       " 'complaints',\n",
       " 'i',\n",
       " 'have',\n",
       " 'about',\n",
       " 'him',\n",
       " ',',\n",
       " 'but',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'really',\n",
       " 'drawing',\n",
       " 'a',\n",
       " 'blank',\n",
       " '.',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_index = []\n",
    "for i in range(len(new_text)):\n",
    "    new_text_index.append([word_embeddings.word_indexer.index_of(word) for word in new_text[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_text_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_text_index)):\n",
    "    if len(new_text_index[i]) != 512:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(new_text_index, dtype='int32')\n",
    "label = np.array(label, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"yelp_data.npy\",data)\n",
    "np.save(\"yelp_label.npy\",label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jTFpLy3EVtD"
   },
   "source": [
    "### Try Ag_news dataset as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxDBfiIoQAE1"
   },
   "outputs": [],
   "source": [
    "# dataset = load_dataset('ag_news')\n",
    "\n",
    "# text=[]\n",
    "# label=[]\n",
    "# for row in dataset['train']['text']+dataset['test']['text']:\n",
    "#     text.append(wordpunct_tokenize(row.lower()))\n",
    "# for row in dataset['train']['label']+dataset['test']['label']:\n",
    "#     label.append(row)\n",
    "\n",
    "# word_dict={'PADDING':0}\n",
    "# for sent in text:    \n",
    "#     for token in sent:        \n",
    "#         if token not in word_dict:\n",
    "#             word_dict[token]=len(word_dict)\n",
    "\n",
    "# news_words = []\n",
    "# for sent in text:       \n",
    "#     sample=[]\n",
    "#     for token in sent:     \n",
    "#         sample.append(word_dict[token])\n",
    "#     sample = sample[:256]\n",
    "#     news_words.append(sample+[0]*(256-len(sample)))\n",
    "\n",
    "# news_words=np.array(news_words,dtype='int32') \n",
    "# label=np.array(label,dtype='int32') \n",
    "\n",
    "# index=np.arange(len(label))\n",
    "# train_index=index[:120000]\n",
    "# np.random.shuffle(train_index)\n",
    "# test_index=index[120000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vaWLW9VVLbwF"
   },
   "outputs": [],
   "source": [
    "# word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWVBiB7BQAHR"
   },
   "outputs": [],
   "source": [
    "# model = Model(config,outclasses = 4)\n",
    "# import torch.optim as optim\n",
    "# optimizer = optim.Adam([ {'params': model.parameters(), 'lr': 1e-3}])\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCqyWm82c2gx"
   },
   "outputs": [],
   "source": [
    "# for epoch in range(2):\n",
    "\n",
    "#     loss = 0.0\n",
    "#     accuary = 0.0\n",
    "    \n",
    "#     for cnt in range(len(train_index)//64):\n",
    "\n",
    "#         log_ids=news_words[train_index][cnt*64:cnt*64+64,:256]\n",
    "#         targets= label[train_index][cnt*64:cnt*64+64]\n",
    "\n",
    "#         log_ids = torch.LongTensor(log_ids).cuda(non_blocking=True)\n",
    "#         targets = torch.LongTensor(targets).cuda(non_blocking=True)\n",
    "#         bz_loss, y_hat = model(log_ids, targets)\n",
    "#         loss += bz_loss.data.float()\n",
    "#         accuary += acc(targets, y_hat)\n",
    "#         unified_loss=bz_loss\n",
    "#         optimizer.zero_grad()\n",
    "#         unified_loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if cnt % 100== 0:\n",
    "#             print( ' Ed: {}, train_loss: {:.5f}, acc: {:.5f}'.format(cnt * 64, loss.data / (cnt+1), accuary / (cnt+1)))\n",
    "            \n",
    "#     model.eval()\n",
    "#     allpred=[]\n",
    "#     for cnt in range(len(test_index)//64+1):\n",
    "    \n",
    "#         log_ids=news_words[test_index][cnt*64:cnt*64+64,:256]\n",
    "#         targets= label[test_index][cnt*64:cnt*64+64]\n",
    "#         log_ids = torch.LongTensor(log_ids).cuda(non_blocking=True)\n",
    "#         targets = torch.LongTensor(targets).cuda(non_blocking=True)\n",
    "    \n",
    "#         bz_loss2, y_hat2 = model(log_ids, targets)\n",
    "#         allpred+=y_hat2.to('cpu').detach().numpy().tolist()\n",
    "        \n",
    "#     y_pred=np.argmax(allpred,axis=-1)\n",
    "#     y_true=label[test_index]\n",
    "\n",
    "#     print(accuracy_score(y_true, y_pred))\n",
    "#     model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLf-gWleGuPk"
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BWNXEnpEhqj"
   },
   "source": [
    "### Train and Test on Amazon Review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuS7Jg0IHBAI"
   },
   "outputs": [],
   "source": [
    "amazon_data = np.load('amazon_review_data.npy')\n",
    "amazon_label = np.load('amazon_review_label.npy')\n",
    "amazon_number_token = int(np.load('amazon_review_num_tokens.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxuBxBKDCi5U"
   },
   "outputs": [],
   "source": [
    "amazon_train_index = [i for i in range(40000)]\n",
    "amazon_val_index = [i for i in range(40000,45000)]\n",
    "amazon_test_index = [i for i in range(45000,50000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbK9__IsCi5V"
   },
   "outputs": [],
   "source": [
    "model = Model(config,outclasses = 5,num_tokens=amazon_number_token)\n",
    "optimizer = optim.Adam([ {'params': model.parameters(), 'lr': 1e-3}])\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f81X9fq7nBQA"
   },
   "outputs": [],
   "source": [
    "amazon_cache,model = train(epochs = 2, \n",
    "                           data = amazon_data , \n",
    "                           label = amazon_label,\n",
    "                           train_index =  amazon_train_index,\n",
    "                           val_index = amazon_val_index)\n",
    "\n",
    "# torch.save({'metrics_cache': amazon_cache,\n",
    "#             'model_dict': model.state_dict()\n",
    "#             }, '/content/drive/MyDrive/nlp_final_project_fastformer/amazon_paramsharing={}.pt'.format(config.param_sharing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhyB5oxvs3dU"
   },
   "source": [
    "#### Result for amazon review dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsNJsS2RtG3R"
   },
   "source": [
    "with parameter sharing:\n",
    "\n",
    "val acc: 0.4368\n",
    "\n",
    "val macro-F: 0.42054310427388086 \n",
    "\n",
    "\n",
    "without parameter sharing:\n",
    "\n",
    "val accuracy 0.442\n",
    "\n",
    "val Macro-F 0.4448873549402369"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DygzHryFs3dU"
   },
   "outputs": [],
   "source": [
    "# with parameter sharing:\n",
    "# val acc: 0.4368\n",
    "# val macro-F: 0.42054310427388086\n",
    "\n",
    "# without parameter sharing:\n",
    "# val accuracy 0.442\n",
    "# val Macro-F 0.4448873549402369"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVMf-ZzVs3dU"
   },
   "outputs": [],
   "source": [
    "with_param_sharing = [0.4368,0.42054310427388086]\n",
    "without_param_sharing = [0.442,0.444873549402369] \n",
    "labels =['Accuracy', 'Macro-F']\n",
    "\n",
    "plot_figure(with_param_sharing,without_param_sharing,labels,set = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fW2WyEmJs3dV"
   },
   "outputs": [],
   "source": [
    "test(model, amazon_data, amazon_label, amazon_test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ay1H2uqRtYBu"
   },
   "source": [
    "with parameter sharing:\n",
    "\n",
    "test acc: 0.4318\n",
    "\n",
    "test macro-F: 0.41902546679396446\n",
    "\n",
    "without parameter sharing:\n",
    "\n",
    "test acc: 0.4346\n",
    "\n",
    "test macro-F:0.43726128296759664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwRcLOeBs3dV"
   },
   "outputs": [],
   "source": [
    "# with parameter sharing:\n",
    "# test acc: 0.4318\n",
    "# test macro-F: 0.41902546679396446\n",
    "\n",
    "# without parameter sharing:\n",
    "# test acc: 0.4346\n",
    "# test macro-F:0.43726128296759664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feRGZCY0s3dV"
   },
   "outputs": [],
   "source": [
    "test_with = [0.4318,0.41902546679396446]\n",
    "test_without = [0.4346,0.43726128296759664]\n",
    "plot_figure(test_with,test_without,labels,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgZ8G95zFvxp"
   },
   "outputs": [],
   "source": [
    "# for epoch in range(2):\n",
    "\n",
    "#     loss = 0.0\n",
    "#     accuary = 0.0\n",
    "#     shuffle(amazon_train_index) \n",
    "#     # np.random.shuffle(amazon_train_index) \n",
    "\n",
    "#     for cnt in range(len(amazon_train_index)//64):\n",
    "\n",
    "#         log_ids=amazon_data[amazon_train_index][cnt*64:cnt*64+64,:config.max_position_embeddings]\n",
    "#         targets= amazon_label[amazon_train_index][cnt*64:cnt*64+64]\n",
    "\n",
    "#         log_ids = torch.LongTensor(log_ids).cuda(non_blocking=True)\n",
    "#         targets = torch.LongTensor(targets).cuda(non_blocking=True)\n",
    "\n",
    "#         bz_loss, y_hat = model(log_ids, targets)\n",
    "\n",
    "#         loss += bz_loss.data.float()\n",
    "#         accuary += acc(targets, y_hat)\n",
    "\n",
    "#         unified_loss=bz_loss\n",
    "#         optimizer.zero_grad()\n",
    "#         unified_loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if cnt % 200 == 0:\n",
    "#             print( ' Ed: {}, train_loss: {:.5f}, acc: {:.5f}'.format(cnt * 64, loss.data / (cnt+1), accuary / (cnt+1)))\n",
    "            \n",
    "#     model.eval()\n",
    "#     allpred=[]\n",
    "#     for cnt in range(len(amazon_val_index)//64+1):\n",
    "    \n",
    "#         log_ids = amazon_data[amazon_val_index][cnt*64:cnt*64+64,:config.max_position_embeddings]\n",
    "#         targets = amazon_label[amazon_val_index][cnt*64:cnt*64+64]\n",
    "#         log_ids = torch.LongTensor(log_ids).cuda(non_blocking=True)\n",
    "#         targets = torch.LongTensor(targets).cuda(non_blocking=True)\n",
    "    \n",
    "#         bz_loss2, y_hat2 = model(log_ids, targets)\n",
    "#         allpred+=y_hat2.to('cpu').detach().numpy().tolist()\n",
    "        \n",
    "#     y_pred = np.argmax(allpred,axis=-1)\n",
    "#     y_true = amazon_label[amazon_val_index]\n",
    "\n",
    "#     print(accuracy_score(y_true, y_pred))\n",
    "#     print(f1_score(y_true, y_pred,average = 'macro'))\n",
    "#     model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNJu4du2iiEH"
   },
   "source": [
    "### Train and test on IMDB review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RcKk5c8ioJ-"
   },
   "outputs": [],
   "source": [
    "imdb_data = np.load('imdb_data.npy')\n",
    "imdb_label = np.load('imdb_label.npy')\n",
    "imdb_label = imdb_label - 1\n",
    "imdb_number_token = int(np.load('imdb_num_tokens.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16raPkCkjb2s"
   },
   "outputs": [],
   "source": [
    "imdb_train_index = [i for i in range(108544)]\n",
    "imdb_val_index = [i for i in range(108544,122106)]\n",
    "imdb_test_index = [i for i in range(122106,135669)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAGLPwNXjflf",
    "outputId": "ba84bae0-a4ab-4a64-e4e5-8e62fb79aada"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (word_embedding): Embedding(1008551, 128, padding_idx=0)\n",
       "  (fastformer_model): FastformerEncoder(\n",
       "    (encoders): ModuleList(\n",
       "      (0): FastformerLayer(\n",
       "        (attention): FastAttention(\n",
       "          (self): AdditiveAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (query_att): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key_att): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (transform): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): FastformerLayer(\n",
       "        (attention): FastAttention(\n",
       "          (self): AdditiveAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (query_att): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key_att): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (transform): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (position_embeddings): Embedding(512, 128)\n",
       "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (poolers): ModuleList(\n",
       "      (0): AttentionPooling(\n",
       "        (att_fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (att_fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense_linear): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(config, outclasses = 10, num_tokens=imdb_number_token)\n",
    "optimizer = optim.Adam([ {'params': model.parameters(), 'lr': 1e-3}])\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2cbSe0tjkt4"
   },
   "outputs": [],
   "source": [
    "imdb_cache,model = train(epochs = 2, \n",
    "                           data = imdb_data , \n",
    "                           label = imdb_label,\n",
    "                           train_index =  imdb_train_index,\n",
    "                           val_index = imdb_val_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0liXmpZBQLm"
   },
   "source": [
    "#### Result for IMDB review dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxZNPesyBUOT"
   },
   "source": [
    "with parameter sharing:\n",
    "\n",
    "val acc: 0.5287568205279457\n",
    "\n",
    "val macro-F: 0.3128399757796875\n",
    "\n",
    "without parameter sharing:\n",
    "\n",
    "val accuracy 0.5306739418964754\n",
    "\n",
    "val Macro-F 0.300849803976839"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MyEqU-fBeM7"
   },
   "outputs": [],
   "source": [
    "with_param_sharing = [0.5287568205279457, 0.3128399757796875]\n",
    "without_param_sharing = [0.5306739418964754, 0.300849803976839] \n",
    "labels =['Accuracy', 'Macro-F']\n",
    "\n",
    "plot_figure(with_param_sharing,without_param_sharing,labels,set = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bE-5wKJmBu0F"
   },
   "outputs": [],
   "source": [
    "test(model, imdb_data, imdb_label, imdb_test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3CQRHK8BkRi"
   },
   "source": [
    "with parameter sharing:\n",
    "\n",
    "test acc: 0.3290569932905699\n",
    "\n",
    "test macro-F: 0.2749917473290363\n",
    "\n",
    "without parameter sharing:\n",
    "\n",
    "test acc: 0.32573914325739145\n",
    "\n",
    "test macro-F:0.2660609692557747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YF9Z7jR-BkqQ"
   },
   "outputs": [],
   "source": [
    "test_with = [ 0.3290569932905699, 0.2749917473290363]\n",
    "test_without = [ 0.32573914325739145, 0.2660609692557747]\n",
    "plot_figure(test_with,test_without,labels,'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nzyf6fg7RdUt"
   },
   "source": [
    "### Try models with pretrained word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G9OnJ5BT6Q2"
   },
   "source": [
    "#### Data and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lb1rGQ3y1hy9"
   },
   "outputs": [],
   "source": [
    "# class Model(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self,config,outclasses,num_tokens):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.config = config\n",
    "#         self.word_embedding = nn.Embedding(num_tokens,config.hidden_size,padding_idx=0)\n",
    "#         self.fastformer_model = FastformerEncoder(config)\n",
    "#         self.dense_linear = nn.Linear(config.hidden_size,outclasses)\n",
    "#         self.criterion = nn.CrossEntropyLoss() \n",
    "#         self.apply(self.init_weights)\n",
    "        \n",
    "#     def init_weights(self, module):\n",
    "#         if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "#             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "#             if isinstance(module, (nn.Embedding)) and module.padding_idx is not None:\n",
    "#                 with torch.no_grad():\n",
    "#                     module.weight[module.padding_idx].fill_(0)\n",
    "#         if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "#             module.bias.data.zero_()\n",
    "    \n",
    "#     def forward(self,input_ids,targets):\n",
    "#         mask=input_ids.bool().float()\n",
    "#         embds=self.word_embedding(input_ids)\n",
    "#         text_vec = self.fastformer_model(embds,mask)\n",
    "#         score = self.dense_linear(text_vec)\n",
    "#         loss = self.criterion(score, targets) \n",
    "#         return loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdqMIBROVEpJ"
   },
   "outputs": [],
   "source": [
    "# class Model_pretrained_emb(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self,config,outclasses,embeddings: word_embeddings ):\n",
    "#         super(Model_pretrained_emb, self).__init__()\n",
    "#         self.config = config\n",
    "#         # self.word_embedding = nn.Embedding(num_tokens,config.hidden_size,padding_idx=0)\n",
    "#         self.word_embedding = embeddings\n",
    "#         self.transform = nn.Linear(50,config.hidden_size)\n",
    "#         self.fastformer_model = FastformerEncoder(config)\n",
    "#         self.dense_linear = nn.Linear(config.hidden_size,outclasses)\n",
    "#         self.criterion = nn.CrossEntropyLoss() \n",
    "#         self.apply(self.init_weights)\n",
    "        \n",
    "#     def init_weights(self, module):\n",
    "#         if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "#             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "#             if isinstance(module, (nn.Embedding)) and module.padding_idx is not None:\n",
    "#                 with torch.no_grad():\n",
    "#                     module.weight[module.padding_idx].fill_(0)\n",
    "#         if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "#             module.bias.data.zero_()\n",
    "    \n",
    "#     def forward(self,input_ids,targets):\n",
    "\n",
    "        \n",
    "#         mask = input_ids.bool().float()\n",
    "\n",
    "\n",
    "#         batch_emb = []\n",
    "#         for batch in range(len(input_ids)):\n",
    "#           embds = []\n",
    "#           for word in input_ids[batch]:\n",
    "#               embds.append(word_embeddings.get_embedding(word))\n",
    "#           batch_emb.append(embds)\n",
    "\n",
    "#         embds_tensor = torch.FloatTensor(np.array(batch_emb)).cuda()\n",
    "\n",
    "#         trans_embds = self.transform(embds_tensor)\n",
    "\n",
    "#         text_vec = self.fastformer_model(trans_embds,mask)\n",
    "#         score = self.dense_linear(text_vec)\n",
    "#         loss = self.criterion(score, targets) \n",
    "#         return loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqQT5JeCOWjx"
   },
   "outputs": [],
   "source": [
    "# word_embeddings.word_indexer.index_of('word')\n",
    "# input_ids= [word_embeddings.word_indexer.index_of(word) for word in ex_words]\n",
    "# len(word_embeddings.word_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "KWLV82ycC1db"
   },
   "outputs": [],
   "source": [
    "amazon_data_new = np.load('amazon_review_data_new_index.npy')\n",
    "amazon_label_new = np.load('amazon_review_label_new_index.npy')\n",
    "\n",
    "amazon_train_index = [i for i in range(40000)]\n",
    "amazon_val_index = [i for i in range(40000,45000)]\n",
    "amazon_test_index = [i for i in range(45000,50000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "lO8C7yWKIyz0"
   },
   "outputs": [],
   "source": [
    "def train(model,epochs, data, label, train_index,val_index):\n",
    "\n",
    "\n",
    "    train_loss_cache = []\n",
    "    train_acc_cache = []\n",
    "    train_f1_cache = []\n",
    "\n",
    "    val_loss_cache = []\n",
    "    val_acc_cache = []\n",
    "    val_f1_cache= []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        loss = 0.0\n",
    "        accuary = 0.0\n",
    "\n",
    "        train_allpred = []\n",
    "\n",
    "        np.random.shuffle(train_index) \n",
    "\n",
    "        for cnt in range(len(train_index)//64):\n",
    "\n",
    "            log_ids = data[train_index][cnt*64:cnt*64+64,:config.max_position_embeddings]\n",
    "            targets = label[train_index][cnt*64:cnt*64+64]\n",
    "\n",
    "            log_ids = torch.LongTensor(log_ids).cuda(non_blocking=True)\n",
    "            targets = torch.LongTensor(targets).cuda(non_blocking=True)\n",
    "\n",
    "            bz_loss, y_hat = model(log_ids, targets)\n",
    "            train_allpred += y_hat.to('cpu').detach().numpy().tolist()\n",
    "\n",
    "            loss += bz_loss.data.float()\n",
    "            accuary += acc(targets, y_hat)\n",
    "\n",
    "            unified_loss=bz_loss\n",
    "            optimizer.zero_grad()\n",
    "            unified_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if cnt % 200== 0:\n",
    "                print( ' Ed: {}, train_loss: {:.5f}, acc: {:.5f}'.format(cnt * 64, loss.data / (cnt+1), accuary / (cnt+1)))\n",
    "\n",
    "        y_pred_train = np.argmax(train_allpred,axis=-1)\n",
    "        y_true_train = label[train_index]  \n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        allpred=[]\n",
    "        val_loss = []\n",
    "\n",
    "        for cnt in range(len(val_index)//64+1):\n",
    "        \n",
    "            log_ids = data[val_index][cnt*64:cnt*64+64,:config.max_position_embeddings]\n",
    "            targets = label[val_index][cnt*64:cnt*64+64]\n",
    "            log_ids = torch.LongTensor(log_ids).cuda(non_blocking=True)\n",
    "            targets = torch.LongTensor(targets).cuda(non_blocking=True)\n",
    "        \n",
    "            bz_loss2, y_hat2 = model(log_ids, targets)\n",
    "            val_loss.append(bz_loss2.data.float())\n",
    "            allpred+=y_hat2.to('cpu').detach().numpy().tolist()\n",
    "            \n",
    "        y_pred = np.argmax(allpred,axis=-1)\n",
    "        y_true = label[val_index]\n",
    "\n",
    "        # print(accuracy_score(y_true, y_pred))\n",
    "        print('Epoch {} val accuracy'.format(epoch),accuracy_score(y_true, y_pred))\n",
    "        print('Epoch {} val Macro-F'.format(epoch),f1_score(y_true, y_pred,average = 'macro'))\n",
    "\n",
    "        train_loss_cache.append(loss.data / (cnt+1))\n",
    "        train_acc_cache.append(accuary / (cnt+1))\n",
    "        train_f1_cache.append(f1_score(y_true_train, y_pred_train ,average = 'macro'))\n",
    "\n",
    "        val_loss_cache.append(sum(val_loss)/len(val_loss))\n",
    "        val_acc_cache.append(accuracy_score(y_true, y_pred))\n",
    "        val_f1_cache.append(f1_score(y_true, y_pred,average = 'macro'))\n",
    "\n",
    "        model.train()\n",
    "\n",
    "    cache = {'train_loss':train_loss_cache,'train_acc':train_acc_cache,'train_f1':train_f1_cache,\n",
    "             'val_loss':val_loss_cache, 'val_acc':val_acc_cache, 'val_f1':val_f1_cache}\n",
    "    return cache, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmGnF4uLIWKS"
   },
   "source": [
    "#### Train and Validation Results for Amazon dataset using 50-300 dimension glove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "otS-SUm7JMXA",
    "outputId": "ecaf7bd4-99cb-4f56-a2ad-64ab0a23d8bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model_pretrained_emb(\n",
       "  (transform): Linear(in_features=50, out_features=256, bias=True)\n",
       "  (fastformer_model): FastformerEncoder(\n",
       "    (encoders): ModuleList(\n",
       "      (0): FastformerLayer(\n",
       "        (attention): FastAttention(\n",
       "          (self): AdditiveAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (query_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (transform): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): FastformerLayer(\n",
       "        (attention): FastAttention(\n",
       "          (self): AdditiveAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (query_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (transform): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (position_embeddings): Embedding(512, 256)\n",
       "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (poolers): ModuleList(\n",
       "      (0): AttentionPooling(\n",
       "        (att_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (att_fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense_linear): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_emb_dim = 50\n",
    "model_50d = Model_pretrained_emb(config,outclasses = 5,embeddings = word_embeddings,pretrained_emb_dim = pretrained_emb_dim)\n",
    "optimizer = optim.Adam([ {'params': model_50d.parameters(), 'lr': 1e-3}])\n",
    "model_50d.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jvYVWpjPJnYz",
    "outputId": "33fb18da-c8f9-4fc1-b33e-527a081a8fe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ed: 0, train_loss: 1.62193, acc: 0.20312\n",
      " Ed: 12800, train_loss: 1.47836, acc: 0.32774\n",
      " Ed: 25600, train_loss: 1.44490, acc: 0.34784\n",
      " Ed: 38400, train_loss: 1.42488, acc: 0.35927\n",
      "Epoch 0 val accuracy 0.3944\n",
      "Epoch 0 val Macro-F 0.3650302795996608\n",
      " Ed: 0, train_loss: 1.29977, acc: 0.39062\n",
      " Ed: 12800, train_loss: 1.35630, acc: 0.40104\n",
      " Ed: 25600, train_loss: 1.34524, acc: 0.40820\n",
      " Ed: 38400, train_loss: 1.34057, acc: 0.41036\n",
      "Epoch 1 val accuracy 0.4028\n",
      "Epoch 1 val Macro-F 0.3670376990575944\n",
      " Ed: 0, train_loss: 1.25017, acc: 0.43750\n",
      " Ed: 12800, train_loss: 1.29669, acc: 0.42382\n",
      " Ed: 25600, train_loss: 1.28806, acc: 0.42947\n",
      " Ed: 38400, train_loss: 1.28784, acc: 0.43152\n",
      "Epoch 2 val accuracy 0.417\n",
      "Epoch 2 val Macro-F 0.378466553811226\n",
      " Ed: 0, train_loss: 1.13393, acc: 0.62500\n",
      " Ed: 12800, train_loss: 1.24574, acc: 0.45826\n",
      " Ed: 25600, train_loss: 1.24481, acc: 0.45484\n",
      " Ed: 38400, train_loss: 1.24877, acc: 0.45466\n",
      "Epoch 3 val accuracy 0.4196\n",
      "Epoch 3 val Macro-F 0.40424968374868187\n",
      " Ed: 0, train_loss: 1.23182, acc: 0.46875\n",
      " Ed: 12800, train_loss: 1.22861, acc: 0.45818\n",
      " Ed: 25600, train_loss: 1.22365, acc: 0.46442\n",
      " Ed: 38400, train_loss: 1.22467, acc: 0.46521\n",
      "Epoch 4 val accuracy 0.4254\n",
      "Epoch 4 val Macro-F 0.4114999892330128\n"
     ]
    }
   ],
   "source": [
    "amazon_cache_50d,model_50d_res = train(model = model_50d, \n",
    "                                       epochs = 5, \n",
    "                                      data = amazon_data_new , \n",
    "                                      label = amazon_label_new,\n",
    "                                      train_index =  amazon_train_index,\n",
    "                                      val_index = amazon_val_index)\n",
    "\n",
    "torch.save({'metrics_cache': amazon_cache_50d,\n",
    "            'model_dict': model_50d_res.state_dict()\n",
    "            }, '/content/drive/MyDrive/nlp_final_project_fastformer/amazon_glove50d_paramsharing={}.pt'.format(config.param_sharing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgPTRESaw1kT"
   },
   "source": [
    "glove50d (with paramsharing):\n",
    "\n",
    "val acc: 0.4254\n",
    "\n",
    "val macro-F: 0.4114999892330128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "D0mQrKHi2QNN"
   },
   "outputs": [],
   "source": [
    "glove_50d_val = [0.4254, 0.4114999892330128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7udmAank3Ro",
    "outputId": "913f6e22-9cfb-45f6-f749-44137642d4fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model_pretrained_emb(\n",
       "  (transform): Linear(in_features=100, out_features=256, bias=True)\n",
       "  (fastformer_model): FastformerEncoder(\n",
       "    (encoders): ModuleList(\n",
       "      (0): FastformerLayer(\n",
       "        (attention): FastAttention(\n",
       "          (self): AdditiveAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (query_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (transform): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): FastformerLayer(\n",
       "        (attention): FastAttention(\n",
       "          (self): AdditiveAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (query_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (transform): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (position_embeddings): Embedding(512, 256)\n",
       "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (poolers): ModuleList(\n",
       "      (0): AttentionPooling(\n",
       "        (att_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (att_fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense_linear): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_emb_dim = 100\n",
    "model_100d = Model_pretrained_emb(config,outclasses = 5,embeddings = word_embeddings_100,pretrained_emb_dim = pretrained_emb_dim)\n",
    "optimizer = optim.Adam([ {'params': model_100d.parameters(), 'lr': 1e-3}])\n",
    "model_100d.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiFiNjI_k3T1",
    "outputId": "5069b4ec-aa4c-40ea-a1a9-e038d3a56f0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ed: 0, train_loss: 1.62106, acc: 0.17188\n",
      " Ed: 12800, train_loss: 1.49871, acc: 0.31763\n",
      " Ed: 25600, train_loss: 1.44421, acc: 0.34963\n",
      " Ed: 38400, train_loss: 1.40950, acc: 0.36951\n",
      "Epoch 0 val accuracy 0.4076\n",
      "Epoch 0 val Macro-F 0.39320016643723976\n",
      " Ed: 0, train_loss: 1.38965, acc: 0.35938\n",
      " Ed: 12800, train_loss: 1.30195, acc: 0.42428\n",
      " Ed: 25600, train_loss: 1.29391, acc: 0.43119\n",
      " Ed: 38400, train_loss: 1.29014, acc: 0.43188\n",
      "Epoch 1 val accuracy 0.4292\n",
      "Epoch 1 val Macro-F 0.4309119114922053\n",
      " Ed: 0, train_loss: 1.26895, acc: 0.53125\n",
      " Ed: 12800, train_loss: 1.25934, acc: 0.45204\n",
      " Ed: 25600, train_loss: 1.25384, acc: 0.45340\n",
      " Ed: 38400, train_loss: 1.25418, acc: 0.45297\n",
      "Epoch 2 val accuracy 0.4416\n",
      "Epoch 2 val Macro-F 0.42697503834259437\n",
      " Ed: 0, train_loss: 1.11370, acc: 0.56250\n",
      " Ed: 12800, train_loss: 1.23159, acc: 0.46580\n",
      " Ed: 25600, train_loss: 1.22754, acc: 0.46630\n",
      " Ed: 38400, train_loss: 1.22769, acc: 0.46594\n",
      "Epoch 3 val accuracy 0.4206\n",
      "Epoch 3 val Macro-F 0.4258406156482365\n",
      " Ed: 0, train_loss: 1.10308, acc: 0.46875\n",
      " Ed: 12800, train_loss: 1.21709, acc: 0.47046\n",
      " Ed: 25600, train_loss: 1.21247, acc: 0.47179\n",
      " Ed: 38400, train_loss: 1.20645, acc: 0.47736\n",
      "Epoch 4 val accuracy 0.4442\n",
      "Epoch 4 val Macro-F 0.41687280518832087\n"
     ]
    }
   ],
   "source": [
    "amazon_cache_100d,model_100d_res = train(model = model_100d, \n",
    "                                       epochs = 5, \n",
    "                                      data = amazon_data_new , \n",
    "                                      label = amazon_label_new,\n",
    "                                      train_index =  amazon_train_index,\n",
    "                                      val_index = amazon_val_index)\n",
    "\n",
    "torch.save({'metrics_cache': amazon_cache_100d,\n",
    "            'model_dict': model_100d_res.state_dict()\n",
    "            }, '/content/drive/MyDrive/nlp_final_project_fastformer/amazon_glove{}_paramsharing={}.pt'.format(pretrained_emb_dim,config.param_sharing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUvBpVzxxGDg"
   },
   "source": [
    "glove100d (with paramsharing):\n",
    "\n",
    "val acc: 0.4442\n",
    "\n",
    "val macro-F: 0.41687280518832087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "MRBhuQB22VmS"
   },
   "outputs": [],
   "source": [
    "glove_100d_val = [0.4442, 0.41687280518832087]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o7atwQuek3Wr",
    "outputId": "f0a8b906-3c01-43ff-f7d5-d0aa52ce01df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model_pretrained_emb(\n",
       "  (transform): Linear(in_features=200, out_features=256, bias=True)\n",
       "  (fastformer_model): FastformerEncoder(\n",
       "    (encoders): ModuleList(\n",
       "      (0): FastformerLayer(\n",
       "        (attention): FastAttention(\n",
       "          (self): AdditiveAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (query_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (transform): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): FastformerLayer(\n",
       "        (attention): FastAttention(\n",
       "          (self): AdditiveAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (query_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (transform): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (position_embeddings): Embedding(512, 256)\n",
       "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (poolers): ModuleList(\n",
       "      (0): AttentionPooling(\n",
       "        (att_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (att_fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense_linear): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_emb_dim = 200\n",
    "model_200d = Model_pretrained_emb(config,outclasses = 5,embeddings = word_embeddings_200,pretrained_emb_dim = pretrained_emb_dim)\n",
    "optimizer = optim.Adam([ {'params': model_200d.parameters(), 'lr': 1e-3}])\n",
    "model_200d.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QrFo3Zfk3Zb",
    "outputId": "91712dc4-12bc-479f-89d0-0a06eb53a1ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ed: 0, train_loss: 1.65704, acc: 0.15625\n",
      " Ed: 12800, train_loss: 1.45067, acc: 0.35634\n",
      " Ed: 25600, train_loss: 1.39450, acc: 0.38155\n",
      " Ed: 38400, train_loss: 1.36434, acc: 0.39663\n",
      "Epoch 0 val accuracy 0.418\n",
      "Epoch 0 val Macro-F 0.39859595663362396\n",
      " Ed: 0, train_loss: 1.24284, acc: 0.35938\n",
      " Ed: 12800, train_loss: 1.27187, acc: 0.44970\n",
      " Ed: 25600, train_loss: 1.27316, acc: 0.44564\n",
      " Ed: 38400, train_loss: 1.27160, acc: 0.44600\n",
      "Epoch 1 val accuracy 0.4212\n",
      "Epoch 1 val Macro-F 0.4255087297755307\n",
      " Ed: 0, train_loss: 1.15907, acc: 0.51562\n",
      " Ed: 12800, train_loss: 1.25288, acc: 0.45491\n",
      " Ed: 25600, train_loss: 1.24258, acc: 0.46068\n",
      " Ed: 38400, train_loss: 1.23819, acc: 0.46272\n",
      "Epoch 2 val accuracy 0.4498\n",
      "Epoch 2 val Macro-F 0.434674619166315\n",
      " Ed: 0, train_loss: 1.12367, acc: 0.56250\n",
      " Ed: 12800, train_loss: 1.20505, acc: 0.47699\n",
      " Ed: 25600, train_loss: 1.21247, acc: 0.47245\n",
      " Ed: 38400, train_loss: 1.21219, acc: 0.46995\n",
      "Epoch 3 val accuracy 0.445\n",
      "Epoch 3 val Macro-F 0.4500075529248474\n",
      " Ed: 0, train_loss: 1.19474, acc: 0.40625\n",
      " Ed: 12800, train_loss: 1.19083, acc: 0.48539\n",
      " Ed: 25600, train_loss: 1.19255, acc: 0.47989\n",
      " Ed: 38400, train_loss: 1.19640, acc: 0.47868\n",
      "Epoch 4 val accuracy 0.4198\n",
      "Epoch 4 val Macro-F 0.394364511948596\n"
     ]
    }
   ],
   "source": [
    "amazon_cache_200d,model_200d_res = train(model = model_200d, \n",
    "                                       epochs = 5, \n",
    "                                      data = amazon_data_new , \n",
    "                                      label = amazon_label_new,\n",
    "                                      train_index =  amazon_train_index,\n",
    "                                      val_index = amazon_val_index)\n",
    "\n",
    "torch.save({'metrics_cache': amazon_cache_200d,\n",
    "            'model_dict': model_200d_res.state_dict()\n",
    "            }, '/content/drive/MyDrive/nlp_final_project_fastformer/amazon_glove{}_paramsharing={}.pt'.format(pretrained_emb_dim,config.param_sharing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "r30UxV1kxV2S"
   },
   "outputs": [],
   "source": [
    "glove_200d_val = [0.445, 0.45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNItuLu_xWQi"
   },
   "source": [
    "glove200d (with paramsharing):\n",
    "\n",
    "val acc: 0.445\n",
    "\n",
    "val macro-F: 0.4500075529248474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "okyUlGt6l1Vb",
    "outputId": "e2386e17-46ee-44d0-9231-2496e8039de3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model_pretrained_emb(\n",
       "  (transform): Linear(in_features=300, out_features=256, bias=True)\n",
       "  (fastformer_model): FastformerEncoder(\n",
       "    (encoders): ModuleList(\n",
       "      (0): FastformerLayer(\n",
       "        (attention): FastAttention(\n",
       "          (self): AdditiveAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (query_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (transform): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): FastformerLayer(\n",
       "        (attention): FastAttention(\n",
       "          (self): AdditiveAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (query_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (transform): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (position_embeddings): Embedding(512, 256)\n",
       "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (poolers): ModuleList(\n",
       "      (0): AttentionPooling(\n",
       "        (att_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (att_fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense_linear): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_emb_dim = 300\n",
    "model_300d = Model_pretrained_emb(config,outclasses = 5,embeddings = word_embeddings_300,pretrained_emb_dim = pretrained_emb_dim)\n",
    "optimizer = optim.Adam([ {'params': model_300d.parameters(), 'lr': 1e-3}])\n",
    "model_300d.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxdZ9D2El6NH",
    "outputId": "53e0e2d9-325e-4937-f62c-d35235b45803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ed: 0, train_loss: 1.62556, acc: 0.20312\n",
      " Ed: 12800, train_loss: 1.43366, acc: 0.36140\n",
      " Ed: 25600, train_loss: 1.37370, acc: 0.39281\n",
      " Ed: 38400, train_loss: 1.34635, acc: 0.40687\n",
      "Epoch 0 val accuracy 0.4018\n",
      "Epoch 0 val Macro-F 0.3905551365235523\n",
      " Ed: 0, train_loss: 1.25053, acc: 0.48438\n",
      " Ed: 12800, train_loss: 1.25777, acc: 0.44737\n",
      " Ed: 25600, train_loss: 1.25838, acc: 0.44880\n",
      " Ed: 38400, train_loss: 1.25332, acc: 0.45089\n",
      "Epoch 1 val accuracy 0.4406\n",
      "Epoch 1 val Macro-F 0.42949810155118523\n",
      " Ed: 0, train_loss: 1.11882, acc: 0.46875\n",
      " Ed: 12800, train_loss: 1.22145, acc: 0.46175\n",
      " Ed: 25600, train_loss: 1.21778, acc: 0.46614\n",
      " Ed: 38400, train_loss: 1.21804, acc: 0.46794\n",
      "Epoch 2 val accuracy 0.4396\n",
      "Epoch 2 val Macro-F 0.44264162801495066\n",
      " Ed: 0, train_loss: 1.11672, acc: 0.53125\n",
      " Ed: 12800, train_loss: 1.21522, acc: 0.46805\n",
      " Ed: 25600, train_loss: 1.20902, acc: 0.47144\n",
      " Ed: 38400, train_loss: 1.20427, acc: 0.47366\n",
      "Epoch 3 val accuracy 0.4362\n",
      "Epoch 3 val Macro-F 0.43130921719898385\n",
      " Ed: 0, train_loss: 1.22079, acc: 0.43750\n",
      " Ed: 12800, train_loss: 1.18379, acc: 0.48678\n",
      " Ed: 25600, train_loss: 1.18616, acc: 0.48402\n",
      " Ed: 38400, train_loss: 1.18391, acc: 0.48461\n",
      "Epoch 4 val accuracy 0.4522\n",
      "Epoch 4 val Macro-F 0.4342004453226235\n"
     ]
    }
   ],
   "source": [
    "amazon_cache_300d,model_300d_res = train(model = model_300d, \n",
    "                                       epochs = 5, \n",
    "                                      data = amazon_data_new , \n",
    "                                      label = amazon_label_new,\n",
    "                                      train_index =  amazon_train_index,\n",
    "                                      val_index = amazon_val_index)\n",
    "\n",
    "torch.save({'metrics_cache': amazon_cache_300d,\n",
    "            'model_dict': model_300d_res.state_dict()\n",
    "            }, '/content/drive/MyDrive/nlp_final_project_fastformer/amazon_glove{}_paramsharing={}.pt'.format(pretrained_emb_dim,config.param_sharing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6zxrF9FyhfH"
   },
   "source": [
    "glove300d (with paramsharing):\n",
    "\n",
    "val acc: 0.4522\n",
    "\n",
    "val macro-F: 0.4342004453226235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "suwgVnoJ2jvX"
   },
   "outputs": [],
   "source": [
    "glove_300d_val = [0.4522, 0.4342004453226235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46Vni6r9yfld"
   },
   "outputs": [],
   "source": [
    "def test(model, data, label, test_index):\n",
    "    \n",
    "    model.eval()\n",
    "    allpred = []\n",
    "    for cnt in range(len(test_index)//64+1):\n",
    "\n",
    "        log_ids = data[test_index][cnt*64:cnt*64+64,:config.max_position_embeddings]\n",
    "        targets= label[test_index][cnt*64:cnt*64+64]\n",
    "        log_ids = torch.LongTensor(log_ids).cuda(non_blocking=True)\n",
    "        targets = torch.LongTensor(targets).cuda(non_blocking=True)\n",
    "\n",
    "        bz_loss3, y_hat3 = model(log_ids, targets)\n",
    "#         allpred += y_hat3\n",
    "        allpred += y_hat3.to('cpu').detach().numpy().tolist()\n",
    "\n",
    "    y_pred = np.argmax(allpred,axis=-1)\n",
    "    y_true = label[test_index]\n",
    "\n",
    "    print('test accuracy',accuracy_score(y_true, y_pred))\n",
    "    print('test Macro-F',f1_score(y_true, y_pred,average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6dSYucIIpBy"
   },
   "source": [
    "#### Test Results on Amazon dataset using glove 50-300 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "5GqWmqdVrQx6"
   },
   "outputs": [],
   "source": [
    "model_50d = Model_pretrained_emb(config,outclasses = 5,embeddings = word_embeddings,pretrained_emb_dim = 50)\n",
    "model_100d = Model_pretrained_emb(config,outclasses = 5,embeddings = word_embeddings_100,pretrained_emb_dim = 100)\n",
    "model_200d = Model_pretrained_emb(config,outclasses = 5,embeddings = word_embeddings_200,pretrained_emb_dim = 200)\n",
    "model_300d = Model_pretrained_emb(config,outclasses = 5,embeddings = word_embeddings_300,pretrained_emb_dim = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "sJh8L4DWsB-6"
   },
   "outputs": [],
   "source": [
    "amazon_50d = torch.load('/content/drive/MyDrive/nlp_final_project_fastformer/amazon_glove50d_paramsharing=True.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WHppw-qHrQz8",
    "outputId": "6fab3a70-0d7d-417a-af26-d33daf1e1f99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50d.load_state_dict(amazon_50d['model_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4ErnRqfrQ4U",
    "outputId": "d96c73fc-b6b2-4390-af7a-50043c5c0650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.4096\n",
      "test Macro-F 0.3971812759759611\n"
     ]
    }
   ],
   "source": [
    "test(model_50d.cuda(), amazon_data_new, amazon_label_new, amazon_test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-AfchjEvlZr"
   },
   "source": [
    "amazon glove 50d (with paramsharing)\n",
    "\n",
    "test accuracy 0.4096\n",
    "\n",
    "test Macro-F 0.3971812759759611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "BK7Drb1f2yA0"
   },
   "outputs": [],
   "source": [
    "glove_50d_test = [0.4096,0.3971812759759611]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NSmugYLGvOpc",
    "outputId": "4ce4c1bc-1d8e-4ab2-eec7-785aad737a68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.4416\n",
      "test Macro-F 0.4179757038579264\n"
     ]
    }
   ],
   "source": [
    "amazon_100d = torch.load('/content/drive/MyDrive/nlp_final_project_fastformer/amazon_glove100_paramsharing=True.pt', map_location=torch.device('cpu'))\n",
    "model_100d.load_state_dict(amazon_100d['model_dict'])\n",
    "test(model_100d.cuda(), amazon_data_new, amazon_label_new, amazon_test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CJSQUynwlxj"
   },
   "source": [
    "amazon glove 100d (with paramsharing)\n",
    "\n",
    "test accuracy 0.4416\n",
    "\n",
    "test Macro-F 0.4179757038579264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "vvWnUwR623kk"
   },
   "outputs": [],
   "source": [
    "glove_100d_test = [0.4416,0.4179757038579264]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2m5yXND9vOuV",
    "outputId": "4c736e77-2890-4454-876f-1b5bed6e8314"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.426\n",
      "test Macro-F 0.3973358713447165\n"
     ]
    }
   ],
   "source": [
    "amazon_200d = torch.load('/content/drive/MyDrive/nlp_final_project_fastformer/amazon_glove200_paramsharing=True.pt', map_location=torch.device('cpu'))\n",
    "model_200d.load_state_dict(amazon_200d['model_dict'])\n",
    "test(model_200d.cuda(), amazon_data_new, amazon_label_new, amazon_test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gu8eD3cwufq"
   },
   "source": [
    "amazon glove 200d (with paramsharing)\n",
    "\n",
    "test accuracy 0.426\n",
    "\n",
    "test Macro-F 0.3973358713447165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "_K_EXV7n28Q8"
   },
   "outputs": [],
   "source": [
    "glove_200d_test = [0.426,0.3973358713447165]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QouDSiQwRAK",
    "outputId": "814c632b-4dcf-42cc-fdc1-223f0c2a374b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.457\n",
      "test Macro-F 0.4379391751958033\n"
     ]
    }
   ],
   "source": [
    "amazon_300d = torch.load('/content/drive/MyDrive/nlp_final_project_fastformer/amazon_glove300_paramsharing=True.pt', map_location=torch.device('cpu'))\n",
    "model_300d.load_state_dict(amazon_300d['model_dict'])\n",
    "test(model_300d.cuda(), amazon_data_new, amazon_label_new, amazon_test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1If8cE8wu6U"
   },
   "source": [
    "amazon glove 300d (with paramsharing)\n",
    "\n",
    "test accuracy 0.457\n",
    "\n",
    "test Macro-F 0.4379391751958033 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "56P-5PbA1hr7"
   },
   "outputs": [],
   "source": [
    "glove_300d_test = [0.457,0.4379391751958033]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kw8pi8FmI6zL"
   },
   "source": [
    "#### Plot the validation and test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "tGQJQK4cyWMd"
   },
   "outputs": [],
   "source": [
    "def plot_figure(glove_50d,glove_100d,glove_200d,glove_300d,\n",
    "                labels,set):\n",
    "    plt.rcParams['axes.labelsize'] = 16  # xy轴label的size\n",
    "    plt.rcParams['xtick.labelsize'] = 12  # x轴ticks的size\n",
    "    plt.rcParams['ytick.labelsize'] = 14  # y轴ticks的size\n",
    "    # plt.rcParams['legend.fontsize'] = 12  # 图例的size\n",
    "\n",
    "\n",
    "    width = 0.15  # 柱形的宽度\n",
    "    x1_list = []\n",
    "    x2_list = []\n",
    "    x3_list = []\n",
    "    x4_list = []\n",
    "    for i in range(len(glove_50d)):\n",
    "        x1_list.append(i)\n",
    "        x2_list.append(i + width)\n",
    "        x3_list.append(i+ 2*width)\n",
    "        x4_list.append(i+ 3*width)\n",
    "\n",
    "    # plt.figure(figsize=(20, 10), dpi=80)\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_ylim(0, 0.6)\n",
    "    a1 = ax1.bar(x1_list, glove_50d, width=width, color='lightcoral', align='edge', label = 'glove_50d')\n",
    "    \n",
    "\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels()) \n",
    "    ax1.set_title('Accuracy and Macro-F of Different Pretrained Embedding on {} set'.format(set),fontsize = 14)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Macro-F')\n",
    "    ax2.set_ylim(0, 0.6)\n",
    "    a2 = ax2.bar(x2_list, glove_100d, width=width, color='lightblue', align='edge', tick_label=labels,label = 'glove_100d')\n",
    "\n",
    "\n",
    "    ax3 = ax2.twinx()\n",
    "    ax3.set_ylim(0, 0.6)\n",
    "    a3 = ax3.bar(x3_list, glove_200d, width=width, color='darkseagreen', align='edge', tick_label=labels,label = 'glove_200d')\n",
    "\n",
    "\n",
    "    ax4 = ax3.twinx()\n",
    "    ax4.set_ylim(0, 0.6)\n",
    "    a4 = ax4.bar(x4_list, glove_300d, width=width, color='papayawhip', align='edge', tick_label=labels,label = 'glove_300d')\n",
    "\n",
    "    plt.legend(handles = [a1,a2,a3,a4])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "4Ts6EbDR7_AN",
    "outputId": "4458ed03-354f-4489-c99a-863158104f02"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['Accuracy','Macro-F']\n",
    "plot_figure(glove_50d_val,glove_100d_val,glove_200d_val,glove_300d_val,\n",
    "                labels,'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "YDMy51Rj7_CZ",
    "outputId": "d14cb34d-5537-43f1-b53f-a995c6f892bc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_figure(glove_50d_test,glove_100d_test,glove_200d_test,glove_300d_test,\n",
    "                labels,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPXFyBeS7_E9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VJMGBxXtESIe",
    "outputId": "4e9a0c93-d606-4094-8319-a371fa74d9f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [tensor(10.6277),\n",
       "  tensor(9.9152),\n",
       "  tensor(9.6340),\n",
       "  tensor(9.5284),\n",
       "  tensor(9.3603)],\n",
       " 'train_acc': [tensor(3.2326),\n",
       "  tensor(3.5688),\n",
       "  tensor(3.7049),\n",
       "  tensor(3.7518),\n",
       "  tensor(3.8398)],\n",
       " 'train_f1': [0.4005200808433601,\n",
       "  0.4441380658106871,\n",
       "  0.46212983044961176,\n",
       "  0.4682210377870617,\n",
       "  0.4800923319833423],\n",
       " 'val_loss': [tensor(1.3497),\n",
       "  tensor(1.2703),\n",
       "  tensor(1.3092),\n",
       "  tensor(1.3030),\n",
       "  tensor(1.2719)],\n",
       " 'val_acc': [0.4018, 0.4406, 0.4396, 0.4362, 0.4522],\n",
       " 'val_f1': [0.3905551365235523,\n",
       "  0.42949810155118523,\n",
       "  0.44264162801495066,\n",
       "  0.43130921719898385,\n",
       "  0.4342004453226235]}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiaBGuX1EuAA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urwUS7gYEuCT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wi7Zi5OtJC8f"
   },
   "source": [
    "#### Try run more epochs for glove 300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j7FWbvKYEuEf",
    "outputId": "f10080cf-34cc-44c7-9f41-45ec1d9664aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model_pretrained_emb(\n",
       "  (transform): Linear(in_features=300, out_features=256, bias=True)\n",
       "  (fastformer_model): FastformerEncoder(\n",
       "    (encoders): ModuleList(\n",
       "      (0): FastformerLayer(\n",
       "        (attention): FastAttention(\n",
       "          (self): AdditiveAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (query_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (transform): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): FastformerLayer(\n",
       "        (attention): FastAttention(\n",
       "          (self): AdditiveAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (query_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key_att): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (transform): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (position_embeddings): Embedding(512, 256)\n",
       "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (poolers): ModuleList(\n",
       "      (0): AttentionPooling(\n",
       "        (att_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (att_fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense_linear): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_emb_dim = 300\n",
    "model_300d = Model_pretrained_emb(config,outclasses = 5,embeddings = word_embeddings_300,pretrained_emb_dim = pretrained_emb_dim)\n",
    "optimizer = optim.Adam([ {'params': model_300d.parameters(), 'lr': 1e-3}])\n",
    "model_300d.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AD7DYysEuG9",
    "outputId": "a9b2ed35-393a-4374-badf-5e98c842c610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ed: 0, train_loss: 1.62291, acc: 0.15625\n",
      " Ed: 12800, train_loss: 1.39947, acc: 0.37990\n",
      " Ed: 25600, train_loss: 1.35663, acc: 0.40173\n",
      " Ed: 38400, train_loss: 1.34021, acc: 0.41012\n",
      "Epoch 0 val accuracy 0.4322\n",
      "Epoch 0 val Macro-F 0.4272291001676498\n",
      " Ed: 0, train_loss: 1.23573, acc: 0.45312\n",
      " Ed: 12800, train_loss: 1.26895, acc: 0.44535\n",
      " Ed: 25600, train_loss: 1.25772, acc: 0.45036\n",
      " Ed: 38400, train_loss: 1.25146, acc: 0.45196\n",
      "Epoch 1 val accuracy 0.4398\n",
      "Epoch 1 val Macro-F 0.4412694183887772\n",
      " Ed: 0, train_loss: 1.17224, acc: 0.53125\n",
      " Ed: 12800, train_loss: 1.21546, acc: 0.47069\n",
      " Ed: 25600, train_loss: 1.22401, acc: 0.46287\n",
      " Ed: 38400, train_loss: 1.22433, acc: 0.46514\n",
      "Epoch 2 val accuracy 0.4442\n",
      "Epoch 2 val Macro-F 0.43202334690938243\n",
      " Ed: 0, train_loss: 1.23071, acc: 0.45312\n",
      " Ed: 12800, train_loss: 1.19973, acc: 0.47691\n",
      " Ed: 25600, train_loss: 1.19780, acc: 0.47810\n",
      " Ed: 38400, train_loss: 1.19863, acc: 0.47769\n",
      "Epoch 3 val accuracy 0.4432\n",
      "Epoch 3 val Macro-F 0.4342910795643259\n",
      " Ed: 0, train_loss: 1.28421, acc: 0.45312\n",
      " Ed: 12800, train_loss: 1.17702, acc: 0.49090\n",
      " Ed: 25600, train_loss: 1.18331, acc: 0.48776\n",
      " Ed: 38400, train_loss: 1.18538, acc: 0.48573\n",
      "Epoch 4 val accuracy 0.4554\n",
      "Epoch 4 val Macro-F 0.4476253785916521\n",
      " Ed: 0, train_loss: 1.16445, acc: 0.56250\n",
      " Ed: 12800, train_loss: 1.16706, acc: 0.49300\n",
      " Ed: 25600, train_loss: 1.16919, acc: 0.49143\n",
      " Ed: 38400, train_loss: 1.17257, acc: 0.49048\n",
      "Epoch 5 val accuracy 0.449\n",
      "Epoch 5 val Macro-F 0.43317375438700606\n",
      " Ed: 0, train_loss: 1.33720, acc: 0.42188\n",
      " Ed: 12800, train_loss: 1.15500, acc: 0.50404\n",
      " Ed: 25600, train_loss: 1.15475, acc: 0.50094\n"
     ]
    }
   ],
   "source": [
    "amazon_cache_300d,model_300d_res = train(model = model_300d, \n",
    "                                       epochs = 20, \n",
    "                                      data = amazon_data_new , \n",
    "                                      label = amazon_label_new,\n",
    "                                      train_index =  amazon_train_index,\n",
    "                                      val_index = amazon_val_index)\n",
    "\n",
    "torch.save({'metrics_cache': amazon_cache_300d,\n",
    "            'model_dict': model_300d_res.state_dict()\n",
    "            }, '/content/drive/MyDrive/nlp_final_project_fastformer/amazon_glove{}_paramsharing={}_20epochs.pt'.format(pretrained_emb_dim,config.param_sharing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TsSlBLl6TM3"
   },
   "source": [
    "### Try without mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRBL4NwoOFSC"
   },
   "outputs": [],
   "source": [
    "def acc(y_true, y_hat):\n",
    "    y_hat = torch.argmax(y_hat, dim=-1)\n",
    "    tot = y_true.shape[0]\n",
    "    hit = torch.sum(y_true == y_hat)\n",
    "    return hit.data.float() * 1.0 / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5OtUQ0UJ0MS"
   },
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.att_fc1 = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.att_fc2 = nn.Linear(config.hidden_size, 1)\n",
    "        self.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "            \n",
    "                \n",
    "    def forward(self, x):\n",
    "        bz = x.shape[0]\n",
    "        e = self.att_fc1(x)\n",
    "        e = nn.Tanh()(e)\n",
    "        alpha = self.att_fc2(e)\n",
    "        alpha = torch.exp(alpha)\n",
    "        # if attn_mask is not None:\n",
    "        #     alpha = alpha * attn_mask.unsqueeze(2)\n",
    "        alpha = alpha / (torch.sum(alpha, dim=1, keepdim=True) + 1e-8)\n",
    "        x = torch.bmm(x.permute(0, 2, 1), alpha)\n",
    "        x = torch.reshape(x, (bz, -1))  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAurc-DD3sxI"
   },
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        if config.hidden_size % config.num_attention_heads != 0:\n",
    "            raise ValueError(\n",
    "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
    "                \"heads (%d)\" %\n",
    "                (config.hidden_size, config.num_attention_heads))\n",
    "            \n",
    "        self.attention_head_size = int(config.hidden_size /config.num_attention_heads)\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "        self.emb_dim = config.hidden_size\n",
    "#         self.emb_dim = 50\n",
    "\n",
    "        self.query = nn.Linear(self.emb_dim, self.all_head_size)\n",
    "        self.query_att = nn.Linear(self.all_head_size, self.num_attention_heads)\n",
    "\n",
    "        self.key = nn.Linear(self.emb_dim, self.all_head_size)\n",
    "        self.key_att = nn.Linear(self.all_head_size, self.num_attention_heads)\n",
    "\n",
    "        self.value = nn.Linear(self.emb_dim, self.all_head_size)\n",
    "\n",
    "        self.transform = nn.Linear(self.all_head_size, self.all_head_size)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "        self.param_sharing = config.param_sharing\n",
    "\n",
    "    def init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "                \n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads,self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # input:(batch_size, seq_len, emb_dim)\n",
    "        batch_size, seq_len, _ = input.shape\n",
    "\n",
    "        # concatenated Q matrix for all heads (batch_size, seq_len, all_head_size)\n",
    "        concat_Q = self.query(input)\n",
    "        # concatenated K matrix for all heads (batch_size, seq_len, all_head_size)\n",
    "        concat_K = self.key(input)\n",
    "\n",
    "        # (batch_size, num_head, seq_len)\n",
    "        query_for_score = self.query_att(concat_Q).transpose(1, 2) / self.attention_head_size**0.5\n",
    "        # add attention mask\n",
    "        # query_for_score += attention_mask\n",
    "\n",
    "        # the weight alpha : (batch_size, num_head, 1, seq_len)\n",
    "        query_weight = self.softmax(query_for_score).unsqueeze(2)\n",
    "\n",
    "        # (batch_size, num_head, seq_len, head_dim)\n",
    "        byhead_Q = self.transpose_for_scores(concat_Q)\n",
    "        # weighted sum of q, get the global representation of q \n",
    "        # after transpose: (batch_size, 1, num_head, head_dim)\n",
    "        # after view: (batch_size, 1, num_head* head_dim)\n",
    "        global_q = torch.matmul(query_weight, byhead_Q).transpose(1, 2).view(-1,1,self.num_attention_heads*self.attention_head_size)\n",
    "        # (batch_size, seq_len, num_head* head_dim)\n",
    "        global_q_matrix = global_q.repeat(1, seq_len,1)\n",
    "        \n",
    "\n",
    "        # global q dot product with k (batch_size, seq_len, all_head_size)\n",
    "        P = concat_K * global_q_matrix\n",
    "        # (batch_size, num_head, seq_len)\n",
    "        P_for_score = (self.key_att(P)/ self.attention_head_size**0.5).transpose(1, 2)\n",
    "        # add attention mask\n",
    "        # P_for_score +=attention_mask\n",
    "\n",
    "        # the weight beta (batch_size, num_head, 1, seq_len)\n",
    "        query_key_weight = self.softmax(P_for_score).unsqueeze(2)\n",
    "        # (batch_size, num_head, seq_len, head_dim)\n",
    "        byhead_P = self.transpose_for_scores(P)\n",
    "        # (batch_size, num_head, 1, head_dim)\n",
    "        global_k = torch.matmul(query_key_weight, byhead_P)\n",
    "\n",
    "        if self.param_sharing:\n",
    "            # query-value parameter sharing\n",
    "            # (batch_size, num_head, 1, head_dim) (batch_size, num_head, seq_len, head_dim) -> (batch_size, num_head, seq_len, head_dim)\n",
    "            # after transpose: (batch_size, seq_len, num_head,  head_dim)\n",
    "            weighted_value =(global_k * byhead_Q).transpose(1, 2)\n",
    "\n",
    "        else:\n",
    "            # without query value param sharing\n",
    "            concat_V = self.value(input)\n",
    "            byhead_V = self.transpose_for_scores(concat_V)\n",
    "\n",
    "            weighted_value =(global_k * byhead_V).transpose(1, 2)\n",
    "\n",
    "\n",
    "        # (batch_size, seq_len, num_head*head_dim)\n",
    "        weighted_value = weighted_value.reshape(weighted_value.size()[:-2] + (self.num_attention_heads * self.attention_head_size,))\n",
    "        # add the original Q as a residual\n",
    "        weighted_value = self.transform(weighted_value) + concat_Q\n",
    "      \n",
    "        return weighted_value\n",
    "\n",
    "class FastAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FastAttention, self).__init__()\n",
    "        self.self = AdditiveAttention(config)\n",
    "        self.output = BertSelfOutput(config)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        self_output = self.self(input_tensor)\n",
    "        attention_output = self.output(self_output, input_tensor)\n",
    "        return attention_output\n",
    "\n",
    "\n",
    "\n",
    "class FastformerLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FastformerLayer, self).__init__()\n",
    "        self.attention = FastAttention(config)\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        attention_output = self.attention(hidden_states)\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        return layer_output\n",
    "\n",
    "class FastformerEncoder(nn.Module):\n",
    "    def __init__(self, config, pooler_count=1):\n",
    "        super(FastformerEncoder, self).__init__()\n",
    "        self.config = config\n",
    "        self.encoders = nn.ModuleList([FastformerLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "#         self.position_embeddings = nn.Embedding(config.max_position_embeddings, 50)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "        # support multiple different poolers with shared bert encoder.\n",
    "        self.poolers = nn.ModuleList()\n",
    "        if config.pooler_type == 'weightpooler':\n",
    "            for _ in range(pooler_count):\n",
    "                self.poolers.append(AttentionPooling(config))\n",
    "        # logging.info(f\"This model has {len(self.poolers)} poolers.\")\n",
    "\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if isinstance(module, (nn.Embedding)) and module.padding_idx is not None:\n",
    "                with torch.no_grad():\n",
    "                    module.weight[module.padding_idx].fill_(0)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, \n",
    "                input_embs, \n",
    "                pooler_index=0):\n",
    "        #input_embs: batch_size, seq_len, emb_dim\n",
    "        #attention_mask: batch_size, seq_len, emb_dim\n",
    "\n",
    "        # extended_attention_mask = attention_mask.unsqueeze(1)\n",
    "        # extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
    "        # extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        batch_size, seq_length, emb_dim = input_embs.shape\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_embs.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand(batch_size, -1)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "\n",
    "        embeddings = input_embs + position_embeddings\n",
    "        \n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        #print(embeddings.size())\n",
    "        all_hidden_states = [embeddings]\n",
    "\n",
    "        for i, layer_module in enumerate(self.encoders):\n",
    "            layer_outputs = layer_module(all_hidden_states[-1])\n",
    "            all_hidden_states.append(layer_outputs)\n",
    "        assert len(self.poolers) > pooler_index\n",
    "        output = self.poolers[pooler_index](all_hidden_states[-1])\n",
    "\n",
    "        return output \n",
    "\n",
    "\n",
    "class Model_pretrained_emb(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,config,outclasses,embeddings: word_embeddings ):\n",
    "        super(Model_pretrained_emb, self).__init__()\n",
    "        self.config = config\n",
    "        # self.word_embedding = nn.Embedding(num_tokens,config.hidden_size,padding_idx=0)\n",
    "        self.word_embedding = embeddings\n",
    "        self.transform = nn.Linear(50,config.hidden_size)\n",
    "        self.fastformer_model = FastformerEncoder(config)\n",
    "        self.dense_linear = nn.Linear(config.hidden_size,outclasses)\n",
    "        self.criterion = nn.CrossEntropyLoss() \n",
    "        self.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if isinstance(module, (nn.Embedding)) and module.padding_idx is not None:\n",
    "                with torch.no_grad():\n",
    "                    module.weight[module.padding_idx].fill_(0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "    \n",
    "    def forward(self,input_ids,targets):\n",
    "        # mask = input_ids.bool().float()\n",
    "        # batch_emb = []\n",
    "        # for batch in range(len(input_ids)):\n",
    "        #   embds = []\n",
    "        #   for word in input_ids[batch]:\n",
    "        #       embds.append(word_embeddings.get_embedding(word))\n",
    "        #   batch_emb.append(embds)\n",
    "\n",
    "        batch_emb = [[word_embeddings.get_embedding(word) for word in input_ids[batch] ] for batch in range(len(input_ids)) ]\n",
    "\n",
    "        embds_tensor = torch.FloatTensor(np.array(batch_emb)).cuda()\n",
    "        \n",
    "        # # embds=self.word_embedding(input_ids)\n",
    "\n",
    "        # embds = []\n",
    "        # for word in ex_words:\n",
    "        #     # print(word)\n",
    "        #     embds.append(self.word_embeddings.get_embedding(word))\n",
    "        # embds_tensor = torch.FloatTensor(np.array(embds))\n",
    "\n",
    "        trans_embds = self.transform(embds_tensor)\n",
    "\n",
    "        text_vec = self.fastformer_model(trans_embds)\n",
    "        score = self.dense_linear(text_vec)\n",
    "        loss = self.criterion(score, targets) \n",
    "        return loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKLfdDbzNl-y"
   },
   "outputs": [],
   "source": [
    "model = Model_pretrained_emb(config,outclasses = 5,embeddings = word_embeddings)\n",
    "optimizer = optim.Adam([ {'params': model.parameters(), 'lr': 1e-3}])\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUt1jmuIQGPg"
   },
   "outputs": [],
   "source": [
    "amazon_data_new = np.load('amazon_review_data_new_index.npy')\n",
    "amazon_label_new = np.load('amazon_review_label_new_index.npy')\n",
    "\n",
    "amazon_train_index = [i for i in range(40000)]\n",
    "amazon_val_index = [i for i in range(40000,45000)]\n",
    "amazon_test_index = [i for i in range(45000,50000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "id": "lLQPAdTwN0P8",
    "outputId": "c7dd7b24-9ba5-4acc-ecbd-6184087999d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ed: 0, train_loss: 1.60870, acc: 0.15625\n",
      " Ed: 12800, train_loss: 1.56944, acc: 0.26757\n",
      " Ed: 25600, train_loss: 1.50983, acc: 0.31156\n",
      " Ed: 38400, train_loss: 1.46817, acc: 0.33481\n",
      "Epoch 0 val accuracy 0.376\n",
      "Epoch 0 val Macro-F 0.3103821815280262\n",
      " Ed: 0, train_loss: 1.40611, acc: 0.32812\n",
      " Ed: 12800, train_loss: 1.35450, acc: 0.40765\n",
      " Ed: 25600, train_loss: 1.34931, acc: 0.40430\n",
      " Ed: 38400, train_loss: 1.33903, acc: 0.40646\n",
      "Epoch 1 val accuracy 0.3828\n",
      "Epoch 1 val Macro-F 0.30653450769023494\n",
      " Ed: 0, train_loss: 1.42712, acc: 0.39062\n",
      " Ed: 12800, train_loss: 1.29949, acc: 0.42351\n",
      " Ed: 25600, train_loss: 1.29190, acc: 0.42901\n",
      " Ed: 38400, train_loss: 1.28730, acc: 0.42980\n",
      "Epoch 2 val accuracy 0.4212\n",
      "Epoch 2 val Macro-F 0.4049859693588919\n",
      " Ed: 0, train_loss: 1.38571, acc: 0.32812\n",
      " Ed: 12800, train_loss: 1.26548, acc: 0.44216\n",
      " Ed: 25600, train_loss: 1.25652, acc: 0.44818\n",
      " Ed: 38400, train_loss: 1.25233, acc: 0.44936\n",
      "Epoch 3 val accuracy 0.4288\n",
      "Epoch 3 val Macro-F 0.3851962205916279\n",
      " Ed: 0, train_loss: 1.29483, acc: 0.42188\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0dbff3eff39c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                            \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamazon_label_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mamazon_train_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                            val_index = amazon_val_index)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-da46cc231672>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, data, label, train_index, val_index)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mbz_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mtrain_allpred\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-781fb4acf8cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, targets)\u001b[0m\n\u001b[1;32m    221\u001b[0m           \u001b[0membds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m               \u001b[0membds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m           \u001b[0mbatch_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-51a77fc809bd>\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(self, word_idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# word_idx = self.word_indexer.index_of(word)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_indexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UNK\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "amazon_cache_new,model = train(epochs = 5, \n",
    "                           data = amazon_data_new , \n",
    "                           label = amazon_label_new,\n",
    "                           train_index =  amazon_train_index,\n",
    "                           val_index = amazon_val_index)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "E9ZInjmjFGY7",
    "W-FpvrNSE5Pi",
    "9jTFpLy3EVtD",
    "nhyB5oxvs3dU",
    "yNJu4du2iiEH",
    "-TsSlBLl6TM3"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
